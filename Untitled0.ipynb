{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEKlN0YivEl5pRe0oQ5BVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishita95-harvad/Ishitatheresearchanalyst.github.io/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazon Product Reviews Workflow for Collaborative Item-Based Filtering"
      ],
      "metadata": {
        "id": "BUjZy7NfUlau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        "\n",
        "This document outlines a structured workflow for analyzing Amazon product reviews using Collaborative Item-Based Filtering. The approach aims to improve recommendation systems by leveraging user interactions with products."
      ],
      "metadata": {
        "id": "Ay14OMb9Ur0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Workflow Stages\n",
        "\n",
        "A. Data Acquisition"
      ],
      "metadata": {
        "id": "YUIToUwfUwg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os # Import the os module\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/irvifa/amazon-product-reviews\")\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Define the expected directory and filename\n",
        "dataset_directory = os.path.join(current_directory, \"amazon-product-reviews\")\n",
        "dataset_filename = \"amazon_co-ecommerce_sample.csv\"  # Update with actual filename if different\n",
        "\n",
        "# Construct the full file path\n",
        "file_path = os.path.join(dataset_directory, dataset_filename)\n",
        "# Check if the file exists\n",
        "if os.path.exists(\"amazon_co-ecommerce_sample.csv\"):\n",
        "    # Load the dataset  # Indented this block to be part of the 'if' statement\n",
        "    reviews_df = pd.read_csv(\"amazon_co-ecommerce_sample.csv\")\n",
        "\n",
        "    # Initial Data Exploration\n",
        "    print(reviews_df.head())\n",
        "    print(reviews_df.info())\n",
        "else:\n",
        "    print(f\"Error: File not found at {'amazon_co-ecommerce_sample.csv'}\")\n",
        "    print(\"Please ensure the dataset was downloaded and the filename is correct.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP5y-Z3kYb-K",
        "outputId": "57d9b8eb-f8c4-4811-ee2c-98489df55827"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Skipping, found downloaded files in \"./amazon-product-reviews\" (use force=True to force download)\n",
            "Error: File not found at amazon_co-ecommerce_sample.csv\n",
            "Please ensure the dataset was downloaded and the filename is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Data Preprocessing"
      ],
      "metadata": {
        "id": "cq3i3tT5U6X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets  # Install opendatasets if not already installed\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os # Import the os module\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/irvifa/amazon-product-reviews\")\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Define the expected directory and filename\n",
        "dataset_directory = os.path.join(current_directory, \"amazon-product-reviews\")\n",
        "dataset_filename = \"amazon_co-ecommerce_sample.csv\"  # Update with actual filename if different\n",
        "\n",
        "# Construct the full file path\n",
        "file_path = os.path.join(dataset_directory, dataset_filename)\n",
        "# Check if the file exists\n",
        "if os.path.exists(\"amazon_co-ecommerce_sample.csv\"):\n",
        "    # Load the dataset  # Indented this block to be part of the 'if' statement\n",
        "    reviews_df = pd.read_csv(\"amazon_co-ecommerce_sample.csv\")\n",
        "\n",
        "    # Initial Data Exploration\n",
        "    print(reviews_df.head())\n",
        "    print(reviews_df.info())\n",
        "\n",
        "    # Remove duplicate and null values #Moved this block into the if condition\n",
        "    reviews_df.drop_duplicates(inplace=True)\n",
        "    reviews_df.dropna(inplace=True)\n",
        "\n",
        "    # Convert textual reviews into numerical ratings (if applicable)\n",
        "    reviews_df['rating'] = reviews_df['rating'].astype(float)\n",
        "\n",
        "    # Normalize ratings\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    reviews_df[['rating']] = scaler.fit_transform(reviews_df[['rating']])\n",
        "\n",
        "    # Create user-item interaction matrix\n",
        "    user_item_matrix = reviews_df.pivot(index='user_id', columns='product_id', values='rating').fillna(0)\n",
        "else:\n",
        "    print(f\"Error: File not found at {'amazon_co-ecommerce_sample.csv'}\")\n",
        "    print(\"Please ensure the dataset was downloaded and the filename is correct.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyCH7S5O0CcG",
        "outputId": "6493548c-3fa8-4b4b-c260-e89efd254937"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Skipping, found downloaded files in \"./amazon-product-reviews\" (use force=True to force download)\n",
            "Error: File not found at amazon_co-ecommerce_sample.csv\n",
            "Please ensure the dataset was downloaded and the filename is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Similarity Computation"
      ],
      "metadata": {
        "id": "Ghlw_HQ-Va2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets  # Install opendatasets if not already installed\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import os  # Import the os module\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np  # Import numpy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/irvifa/amazon-product-reviews\")\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Define the expected directory and filename\n",
        "dataset_directory = os.path.join(current_directory, \"amazon-product-reviews\")\n",
        "dataset_filename = \"amazon_co-ecommerce_sample.csv\"  # Update with actual filename if different\n",
        "\n",
        "# Construct the full file path\n",
        "file_path = os.path.join(dataset_directory, dataset_filename)\n",
        "\n",
        "# Check if the file exists\n",
        "# Use file_path instead of just the filename\n",
        "if os.path.exists(file_path):\n",
        "    # Load the dataset\n",
        "    reviews_df = pd.read_csv(file_path)  # Use file_path to read the CSV\n",
        "\n",
        "    # Initial Data Exploration\n",
        "    print(reviews_df.head())\n",
        "    print(reviews_df.info())\n",
        "\n",
        "    # Remove duplicate and null values\n",
        "    reviews_df.drop_duplicates(inplace=True)\n",
        "    reviews_df.dropna(inplace=True)\n",
        "\n",
        "    # Convert textual reviews into numerical ratings (if applicable)\n",
        "    reviews_df['rating'] = reviews_df['rating'].astype(float)\n",
        "\n",
        "    # Normalize ratings\n",
        "    scaler = MinMaxScaler()\n",
        "    reviews_df[['rating']] = scaler.fit_transform(reviews_df[['rating']])\n",
        "\n",
        "    # **Ensure product_id is treated as a string**\n",
        "    reviews_df['product_id'] = reviews_df['product_id'].astype(str)\n",
        "\n",
        "    # Create user-item interaction matrix\n",
        "    user_item_matrix = reviews_df.pivot(\n",
        "        index='user_id', columns='product_id', values='rating'\n",
        "    ).fillna(0)\n",
        "\n",
        "    # Calculate cosine similarity between products\n",
        "    item_similarity = cosine_similarity(user_item_matrix.T)\n",
        "\n",
        "    # Convert the similarity matrix to a DataFrame for easier handling\n",
        "    item_similarity_df = pd.DataFrame(\n",
        "        item_similarity,\n",
        "        index=user_item_matrix.columns,\n",
        "        columns=user_item_matrix.columns,\n",
        "    )\n",
        "\n",
        "    # Print some similarity values (optional)\n",
        "    print(item_similarity_df.head())\n",
        "\n",
        "else:\n",
        "    print(f\"Error: File not found at {file_path}\")  # Print the full file path\n",
        "    print(\"Please ensure the dataset was downloaded and the filename is correct.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOC2vP8kAAWW",
        "outputId": "bb5c030a-9ad1-4c91-e68a-a0b18ffe86fb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Skipping, found downloaded files in \"./amazon-product-reviews\" (use force=True to force download)\n",
            "Error: File not found at /content/amazon-product-reviews/amazon_co-ecommerce_sample.csv\n",
            "Please ensure the dataset was downloaded and the filename is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Recommendation Generation"
      ],
      "metadata": {
        "id": "2T79vrmAVBSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recommend similar items\n",
        "def recommend_items(item, similarity_matrix, num_recommendations=5):\n",
        "    \"\"\"\n",
        "    Recommends items similar to the given item based on cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        item (str): The ID of the item for which to generate recommendations.\n",
        "        similarity_matrix (pd.DataFrame): The item-item similarity matrix.\n",
        "        num_recommendations (int, optional): The number of recommendations to generate. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A Series containing the recommended item IDs and their similarity scores.\n",
        "                   Returns an error message if the item is not found in the similarity matrix.\n",
        "    \"\"\"\n",
        "    if item not in similarity_matrix.columns:\n",
        "        return \"Item not found in similarity matrix\"\n",
        "\n",
        "    similar_items = similarity_matrix[item].sort_values(ascending=False)[1:num_recommendations+1]\n",
        "    # [1:] Excludes the item itself from recommendations\n",
        "    return similar_items\n",
        "\n",
        "# Assuming item_similarity_df was created in a previous cell\n",
        "# If not, make sure to define or load it before running this code\n",
        "# Example usage\n",
        "# Replace 'B0000SX2UC' with an actual product ID from your dataset that exists in item_similarity_df\n",
        "item_to_recommend = '0594451647' # Replacing with a product id that exists in the dataset\n",
        "try: #Adding a try-except block to catch the NameError if item_similarity_df is not defined\n",
        "    recommendations = recommend_items(item_to_recommend, item_similarity_df, num_recommendations=10)\n",
        "except NameError:\n",
        "    print(\"item_similarity_df is not defined. Please make sure it is calculated and available in the current scope.\")\n",
        "else:\n",
        "    if isinstance(recommendations, str):  # Check if an error message was returned\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        print(f\"Recommended items for {item_to_recommend}:\\n{recommendations}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMH7R8P3EfH",
        "outputId": "260fd560-c069-4f46-ae84-33de674cc6de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item_similarity_df is not defined. Please make sure it is calculated and available in the current scope.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E. Evaluation and Optimization"
      ],
      "metadata": {
        "id": "sGZ2J9UDVxD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Placeholder function for evaluation (Assuming we have ground-truth labels)\n",
        "def evaluate_model(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    return {\"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1}\n",
        "\n",
        "# Example placeholder for A/B testing (Implementation depends on business setup)\n",
        "def ab_testing(strategy_a, strategy_b):\n",
        "    # Compare two different recommendation strategies\n",
        "    pass\n",
        "\n",
        "# Example of hyperparameter tuning (can be applied to similarity computation, normalization, etc.)\n",
        "def tune_hyperparameters():\n",
        "    # Example: Try different similarity metrics like Pearson correlation\n",
        "    pass"
      ],
      "metadata": {
        "id": "lI5yZlqGVz63"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}